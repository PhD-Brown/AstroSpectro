---
id: faq
title: Foire aux questions
sidebar_position: 5
---

<!-- Complet for v1.0.0 release -->

import { FontAwesomeIcon } from '@fortawesome/react-fontawesome'
import { faQuestionCircle, faDatabase, faCode, faBrain } from '@fortawesome/free-solid-svg-icons'
import Admonition from '@theme/Admonition';

# <FontAwesomeIcon icon={faQuestionCircle} /> Foire Aux Questions (FAQ)

Bienvenue dans la FAQ ! Vous trouverez ici les réponses aux questions les plus fréquemment posées sur le projet **AstroSpectro**.

<Admonition type="note" title="Vous ne trouvez pas votre réponse ?">
  <p>
    Si votre question n'est pas listée ici, n'hésitez pas à <strong><a href="https://github.com/PhD-Brown/AstroSpectro/issues/new/choose">ouvrir une Issue sur GitHub</a></strong> pour la poser à la communauté. Votre question pourrait aider d'autres personnes !
  </p>
</Admonition>

---

### <FontAwesomeIcon icon={faDatabase} /> Questions sur les Données

<details>
  <summary>Puis-je utiliser ce pipeline avec d'autres données que LAMOST DR5 ?</summary>
  <div>
    <p>
      <strong>Pour l'instant, le pipeline est fortement optimisé pour le format spécifique des fichiers FITS de LAMOST DR5.</strong> L'adaptation à d'autres relevés (comme SDSS ou Gaia) nécessiterait de modifier la classe <code>SpectraPreprocessor</code> pour qu'elle puisse interpréter leurs structures de header et de données.
    </p>
    <p>
      Cependant, l'architecture modulaire est conçue pour faciliter ce genre d'extension. Le support multi-survey est une des ambitions majeures listées dans notre <a href="../community/roadmap">Roadmap</a>.
    </p>
  </div>
</details>

<details>
  <summary>Quelle est la taille approximative des données à télécharger ?</summary>
  <div>
    <p>
      Le relevé complet de LAMOST DR5 est immense (plusieurs Téraoctets). Heureusement, vous n'avez pas besoin de tout télécharger !
    </p>
    <p>
      Le pipeline est conçu pour fonctionner par lots. Un lot de <strong>quelques milliers de spectres (quelques Gigaoctets)</strong> est suffisant pour obtenir des résultats très performants (>80% de précision). L'interface de téléchargement interactive vous permet de fixer des limites précises pour contrôler la quantité de données récupérées.
    </p>
  </div>
</details>

---

### <FontAwesomeIcon icon={faCode} /> Questions Techniques

<details>
  <summary>Pourquoi le projet est-il structuré avec des notebooks ET des scripts Python dans <code>src/</code> ?</summary>
  <div>
    <p>
      C'est un choix d'architecture délibéré pour combiner le meilleur des deux mondes :
    </p>
    <ul>
      <li>Les <strong>scripts Python dans <code>src/</code></strong> contiennent la logique métier "pure", organisée en classes modulaires et réutilisables. C'est le "moteur" robuste du projet.</li>
      <li>Les <strong>notebooks Jupyter</strong> servent d'interface utilisateur et de "tableau de bord". Ils permettent d'orchestrer la logique des modules de manière interactive, de visualiser les résultats et de documenter les expériences.</li>
    </ul>
    <p>Cette séparation est une pratique standard dans les projets de science des données professionnels car elle garantit la clarté, la maintenabilité et la testabilité du code.</p>
  </div>
</details>

---

### <FontAwesomeIcon icon={faBrain} /> Questions sur le Machine Learning

<details>
  <summary>Pourquoi utiliser RandomForest et XGBoost plutôt qu'un modèle de Deep Learning ?</summary>
  <div>
    <p>
      Le choix de modèles basés sur les arbres de décision comme <strong>RandomForest</strong> et <strong>XGBoost</strong> est intentionnel et stratégique pour cette phase du projet :
    </p>
    <ul>
      <li><strong>Interprétabilité :</strong> Ces modèles permettent de mesurer facilement l'importance des <em>features</em>. Cela nous a permis de valider notre approche de feature engineering et de comprendre que des mesures comme la largeur des raies (FWHM) ou le redshift étaient cruciales. C'est essentiel dans un contexte de recherche.</li>
      <li><strong>Efficacité :</strong> Ils sont extrêmement rapides à entraîner sur des données tabulaires (nos vecteurs de <em>features</em>), ce qui permet des cycles d'expérimentation très courts.</li>
      <li><strong>Performance :</strong> Comme nos résultats le montrent (>80% de précision), ils sont déjà très performants lorsque nourris avec des <em>features</em> de haute qualité.</li>
    </ul>
    <p>
      Cela dit, l'exploration de modèles de Deep Learning (comme des <strong>CNN 1D</strong>) est une étape clé de notre <a href="../community/roadmap">Roadmap</a>. Ils pourraient potentiellement capturer des motifs subtils dans le spectre brut que notre extraction de <em>features</em> manuelle aurait manqués.
    </p>
  </div>
</details>

<details>
  <summary>Comment gérez-vous le déséquilibre des classes dans le jeu de données ?</summary>
  <div>
    <p>
      C'est un problème fondamental dans les datasets astrophysiques. Notre pipeline intègre une approche à deux niveaux :
    </p>
    <ol>
      <li><strong>Filtrage :</strong> Nous retirons les classes qui sont extrêmement rares (moins de 10 exemples), car il est statistiquement impossible d'entraîner un modèle fiable sur aussi peu de données.</li>
      <li><strong>Sur-échantillonnage (SMOTE) :</strong> Pour les classes minoritaires restantes, nous utilisons la technique <strong>SMOTE</strong> (via la librairie <code>imbalanced-learn</code>) directement dans notre pipeline d'entraînement. SMOTE crée des échantillons synthétiques plausibles pour ces classes, ce qui donne au modèle une vision plus équilibrée des données et améliore significativement sa performance sur les classes sous-représentées.</li>
    </ol>
  </div>
</details>