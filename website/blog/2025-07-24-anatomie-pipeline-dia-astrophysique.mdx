---
title: "Anatomie d'une Am√©lioration"
slug: 2025-07-24-anatomie-pipeline-dia-astrophysique
authors: abaker
tags: ["machine-learning", "results", "feature-engineering", "optimization", "milestone"]
date: 2025-07-24
---

> <span style={{fontSize: "1.3rem", fontWeight: "400", color: "#AAA"}}>Une √©tude de cas sur la mani√®re dont une meilleure extraction de features, guid√©e par des outils de visualisation, a permis d'augmenter la performance d'un mod√®le de 75% par rapport √† sa baseline.</span>  

Apr√®s avoir √©tabli une premi√®re baseline pour notre classifieur spectral, l'aventure ne faisait que commencer. Le premier mod√®le, bien que prometteur avec une pr√©cision de 32%, nous a laiss√© avec une feuille de route claire : pour am√©liorer la performance, il fallait am√©liorer la qualit√© de nos features.

<!--truncate-->

Aujourd'hui, apr√®s plusieurs it√©rations de d√©bogage, d'analyse et d'optimisation, nous avons franchi une √©tape significative, faisant passer la pr√©cision du mod√®le de 32% √† un tr√®s respectable **56%**. Voici le r√©cit de cette progression.

### It√©ration 1 : De la Pr√©sence √† la Force des Raies

La premi√®re am√©lioration consistait √† passer d'une feature binaire (la raie est-elle pr√©sente ?) √† une mesure continue : la **force de la raie**, approxim√©e par la "prominence" du pic d'absorption. Ce changement a eu un impact imm√©diat, faisant grimper notre pr√©cision globale de 32% √† **40%**. Cette √©tape a valid√© que la quantit√© d'information physique contenue dans la force d'une raie √©tait bien plus riche que sa simple pr√©sence.

<details>
  <summary>Voir les r√©sultats en d√©tail</summary>
  ```
Suppression des classes trop rares : ['C']

Features utilis√©es pour l'entra√Ænement : ['feature_HŒ±', 'feature_HŒ≤', 'feature_CaIIK', 'feature_CaIIH']
Nombre d'√©chantillons : 4999, Nombre de features : 4
  > Entra√Ænement du mod√®le sur 3749 √©chantillons...
  > Mod√®le entra√Æn√©.

--- Rapport d'√âvaluation ---
              precision    recall  f1-score   support

           A       0.58      0.64      0.61        73
           B       0.00      0.00      0.00         1
           D       0.00      0.00      0.00         1
           F       0.43      0.43      0.43       255
           G       0.43      0.35      0.38       394
           K       0.34      0.49      0.40       283
           M       0.28      0.18      0.22       158
           N       0.43      0.51      0.46        84
           W       0.00      0.00      0.00         1
           s       0.00      0.00      0.00         0

    accuracy                           0.40      1250
   macro avg       0.25      0.26      0.25      1250
weighted avg     0.40      0.40      0.40      1250

  ```

  ![image info](/img/matrice_02.png)

</details>

### It√©ration 2 : La Puissance des Ratios Spectraux

Avec une nouvelle baseline solide, nous avons introduit des features encore plus sophistiqu√©s : les **ratios de force entre diff√©rentes raies**. En astrophysique, ces ratios sont des indicateurs de temp√©rature extr√™mement puissants.

*   `feature_ratio_CaK_Hbeta = CaII K / HŒ≤`
*   `feature_ratio_Halpha_Hbeta = HŒ± / HŒ≤`

L'ajout de ces deux seuls ratios a de nouveau propuls√© notre mod√®le, atteignant une pr√©cision de **50%**. La matrice de confusion montrait une nette am√©lioration, mais une analyse de la qualit√© des features a r√©v√©l√© une faiblesse critique : la raie HŒ± √©tait absente dans plus de 50% des spectres, rendant les ratios peu fiables.

<details>
  <summary>Voir les r√©sultats en d√©tail</summary>
  ```
--- Chargement du dataset : features_20250723T225208Z.csv ---
  > 250 lignes avec des labels invalides ou nuls supprim√©es.
  > Suppression des classes trop rares : ['W', 'C', 'D', 'B', 's']

Features utilis√©es : ['feature_HŒ±', 'feature_HŒ≤', 'feature_CaIIK', 'feature_CaIIH', 'feature_ratio_CaK_Hbeta', 'feature_ratio_Halpha_Hbeta']
Nombre d'√©chantillons final : 2740, Nombre de features : 6

--- √âTAPE 5: Entra√Ænement et √âvaluation du mod√®le ---
  > Entra√Ænement du mod√®le sur 2055 √©chantillons...
  > Mod√®le entra√Æn√©.

--- Rapport d'√âvaluation ---
              precision    recall  f1-score   support

           A       0.70      0.51      0.59        41
           F       0.54      0.60      0.57       157
           G       0.55      0.58      0.56       230
           K       0.41      0.40      0.41       163
           M       0.34      0.29      0.31        94

    accuracy                           0.50       685
   macro avg       0.51      0.48      0.49       685
weighted avg     0.49      0.50      0.49       685

  ```

![image info](/img/matrice_03.png)
![image info](/img/zero_features_01.png)
![image info](/img/importance_features_01.png)

</details>

### It√©ration Finale : Le Tuning par la Visualisation

C'est √† ce stade que nos outils de visualisation sont devenus cruciaux. L'analyse a montr√© que notre param√®tre de d√©tection de pics (`prominence`) √©tait trop strict et ignorait de nombreuses raies r√©elles mais moins profondes.

Gr√¢ce √† notre **analyseur de spectre interactif**, nous avons pu "tuner" ce param√®tre en temps r√©el. Une valeur optimis√©e de `prominence=0.23` a √©t√© identifi√©e, permettant de r√©cup√©rer un grand nombre de raies auparavant ignor√©es.

![image info](/img/raie_01.png)
![image info](/img/raie_02.png)

### Le R√©sultat Final : Une Pr√©cision de 56%

Apr√®s avoir relanc√© le pipeline complet avec ce param√®tre optimis√© sur un nouveau lot de **2607 spectres**, les r√©sultats ont d√©pass√© nos attentes :

*   **Pr√©cision Globale : 56%**
*   **Qualit√© des Features :** Le probl√®me des valeurs manquantes a √©t√© quasiment √©limin√©, avec toutes les features de base pr√©sentes dans plus de **95%** des cas.
*   **Pertinence des Features :** L'importance des features est maintenant bien mieux √©quilibr√©e. `feature_HŒ≤` et le `ratio_CaK_Hbeta` s'imposent comme les indicateurs les plus puissants, mais toutes les features contribuent d√©sormais de mani√®re significative.

La matrice de confusion finale montre une diagonale bien plus nette, signe d'un mod√®le plus confiant et plus pr√©cis, avec des scores F1 sup√©rieurs √† 0.54 pour toutes les classes principales.

<details>
  <summary>Voir les r√©sultats en d√©tail</summary>
  ```
--- Chargement du dataset : features_20250724T012617Z.csv ---
  > 383 lignes avec des labels invalides ou nuls supprim√©es.
  > Suppression des classes trop rares : ['s', 'B', 'D', 'C']

Features utilis√©es : ['feature_HŒ±', 'feature_HŒ≤', 'feature_CaIIK', 'feature_CaIIH', 'feature_ratio_CaK_Hbeta', 'feature_ratio_Halpha_Hbeta']
Nombre d'√©chantillons final : 2607, Nombre de features : 6

--- √âTAPE 5: Entra√Ænement et √âvaluation du mod√®le ---
  > Entra√Ænement du mod√®le sur 1955 √©chantillons...
  > Mod√®le entra√Æn√©.

--- Rapport d'√âvaluation ---
              precision    recall  f1-score   support

           A       0.54      0.54      0.54        41
           F       0.54      0.55      0.55       140
           G       0.59      0.59      0.59       215
           K       0.59      0.58      0.58       168
           M       0.45      0.46      0.45        87
           W       0.00      0.00      0.00         1

    accuracy                           0.56       652
   macro avg       0.45      0.45      0.45       652
weighted avg     0.55      0.56      0.56       652

  ```

![image info](/img/matrice_04.png)
![image info](/img/missing_features_02.png)
![image info](/img/importance_features_01.png)

</details>

### Conclusion et Prochaines Aventures

Ce sprint de recherche a √©t√© une d√©monstration √©clatante de la puissance de la m√©thode it√©rative en science des donn√©es. En partant d'un mod√®le simple, et en l'am√©liorant √©tape par √©tape en se basant sur l'analyse des r√©sultats, nous avons **am√©lior√© notre baseline de 24 points de pourcentage**.

Le projet AstroSpectro dispose maintenant d'un pipeline de production robuste et d'une suite d'outils d'analyse performants. Les prochaines pistes d'exploration sont d√©j√† sur la table :

*   **Enrichir les features** pour mieux classifier les √©toiles froides (type M) en ajoutant des bandes mol√©culaires.
*   **Exp√©rimenter avec des mod√®les plus puissants** comme XGBoost ou des r√©seaux de neurones.
*   **Passer au Deep Learning** en utilisant le spectre entier comme entr√©e d'un r√©seau de neurones convolutifs (CNN).

Le laboratoire est construit. Les outils sont aff√ªt√©s. L'aventure continue ! üöÄ
