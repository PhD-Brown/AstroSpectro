---
title: "De 32% √† 84% : R√©cit d'une Perc√©e en Classification Stellaire par l'IA"
slug: 2025-08-01-de-32-a-84-pourcent-classifieur-stellaire
authors: abaker
tags: ["machine-learning", "results", "feature-engineering", "optimization", "milestone", "xgboost"]
date: 2025-08-01
---

> <span style={{fontSize: "1.3rem", fontWeight: "400", color: "#AAA"}}>Le√ßon d'astrophysique : quand le feature engineering bat la force brute.</span>

Le voyage du projet AstroSpectro a atteint aujourd'hui un jalon majeur. Ce qui a commenc√© comme une baseline modeste √† **32%** de pr√©cision s'est transform√©, apr√®s une s√©rie d'it√©rations scientifiques rigoureuses, en un classifieur stellaire haute performance atteignant **84%** de pr√©cision. Ce billet retrace les √©tapes cl√©s, les d√©couvertes et les le√ßons apprises au cours de cette aventure.

<!--truncate-->

### Acte I : La Baseline √† 32% - Une Preuve de Concept

Notre point de d√©part √©tait un mod√®le simple, entra√Æn√© sur 5000 spectres avec seulement quatre features : la pr√©sence ou l'absence des raies HŒ±, HŒ≤, CaII H & K. Le r√©sultat, 32%, √©tait plus de trois fois sup√©rieur au hasard et validait notre pipeline. Cependant, l'analyse des r√©sultats a r√©v√©l√© deux faiblesses majeures : 
    1. un fort d√©s√©quilibre des classes, 
    2. des features trop souvent absentes, en particulier HŒ±.

(Pour plus de d√©tails, voir mon [premier billet sur les r√©sultats](https://phd-brown.github.io/AstroSpectro/journal/Premier%20partage%20de%20r%C3%A9sultat)).

### Acte II : L'√àre du Feature Engineering - Vers 75%

La feuille de route √©tait claire : il fallait enrichir nos features. Chaque nouvelle id√©e a √©t√© test√©e m√©thodiquement :

1. **De la Pr√©sence √† la Force (Prominence) :** Mesurer la profondeur des raies a fait passer la pr√©cision √† **40%**.
2. **La Puissance des Ratios :** L'ajout de ratios de force entre les raies (ex: CaII K / HŒ≤) a propuls√© le score √† **50%**.
3. **Le Contexte par les M√©tadonn√©es :** L'inclusion des m√©tadonn√©es du header FITS (redshift, SNR, seeing) a provoqu√© une perc√©e spectaculaire, atteignant **71%**.
4.  **La Forme des Raies (FWHM & Skewness) :** L'ajout de la **largeur √† mi-hauteur (FWHM)** a encore affin√© le mod√®le. Nous avons √©galement test√© l'**asym√©trie (skewness)** des raies. Si le FWHM s'est av√©r√© √™tre un indicateur tr√®s pertinent, le skewness, lui, n'a apport√© aucune am√©lioration. L'analyse a montr√© que cette mesure √©tait trop sensible au bruit r√©siduel, m√™me apr√®s un lissage, et le mod√®le a donc appris √† l'ignorer. C'est une le√ßon importante : toutes les features physiques ne sont pas forc√©ment utiles pour un mod√®le d'IA.
5. **Robustesse par la Validation Crois√©e :** L'int√©gration de ``GridSearchCV`` a permis de trouver les meilleurs hyperparam√®tres et de stabiliser la performance autour d'un tr√®s solide **75%**.

Chaque √©tape √©tait une confirmation : plus nous donnions d'informations physiques et contextuelles au mod√®le, meilleures √©taient ses performances.

### L'Outil Cl√© : Le D√©bogage Interactif

Cette progression n'aurait pas √©t√© possible sans les outils de visualisation d√©velopp√©s en parall√®le. Notre [Analyseur de Spectre Augment√©](https://github.com/PhD-Brown/AstroSpectro/blob/main/notebooks/02_tools_and_visuals.ipynb) est devenu le c≈ìur de notre processus de recherche, nous permettant de :

- **Visualiser** n'importe quel spectre de notre collection.
- **Tuner** les param√®tres de d√©tection de pics en temps r√©el.
- **Comparer** la "vraie" classe d'une √©toile avec la pr√©diction du mod√®le en direct.  

C'est cet outil qui nous a permis d'identifier que nos param√®tres de d√©tection initiaux √©taient trop stricts, nous faisant manquer des informations cruciales.

![Capture d'√©cran de l'Analyseur de Spectre Augment√©](/img/analyseur_spectre_final.png)

### Acte III : Le Challenger XGBoost - La Perc√©e √† 84%

Avec un jeu de features riche et robuste, il √©tait temps de tester un mod√®le plus puissant. Nous avons remplac√© le ``RandomForest`` par un ``XGBoost``, un algorithme de gradient boosting r√©put√© pour ses performances.

Le r√©sultat a √©t√© imm√©diat et spectaculaire.

- **Score de Validation Crois√©e : 82.3%**
- **Pr√©cision finale sur le jeu de test : 84%**

<details>
<summary>Voir les r√©sultats finaux en d√©tail</summary>
```
--- Rapport d'√âvaluation (XGBoost) ---
             precision  recall   f1-score   support
A              0.85      0.79      0.82        29
F              0.79      0.79      0.79        98
G              0.82      0.80      0.81       143
K              0.77      0.85      0.81       101
M              0.94      0.82      0.88        57
N              0.97      1.00      0.99        69

accuracy                           0.84       497
macro avg      0.86      0.84      0.85       497
weighted avg   0.84      0.84      0.84       497
```

![Matrice de Confusion Finale](/img/matrice_finale_xgboost.png)
</details>

La matrice de confusion finale montre une diagonale √©crasante, signe d'un mod√®le extr√™mement confiant et pr√©cis. La confusion entre les classes adjacentes a √©t√© minimis√©e, et la performance est excellente sur l'ensemble des types stellaires principaux.

### L'Anatomie de la D√©cision : Quelles Features Comptent le Plus ?

Le graphique d'importance des features pour notre mod√®le XGBoost final r√©v√®le une hi√©rarchie fascinante. Les m√©tadonn√©es contextuelles comme `redshift_error` et l'indice de couleur dominent, mais elles sont imm√©diatement suivies par les mesures physiques que nous avons extraites, comme la largeur (FWHM) et la force (prominence) des raies HŒ± et HŒ≤. C'est la confirmation que la meilleure performance est atteinte en combinant le **contexte de l'observation** avec les **propri√©t√©s physiques du spectre**.

![Graphique d'Importance des Features Fina](/img/importance_features_final_xgboost.png)

### Conclusion : La Convergence de la Physique et de l'IA

Ce voyage de 32% √† 84% n'est pas seulement l'histoire d'un score qui augmente. C'est la d√©monstration qu'une approche rigoureuse, combinant :
-   Une **architecture logicielle modulaire** et robuste.
-   Un **feature engineering** guid√© par la connaissance du domaine astrophysique.
-   Des **outils de visualisation interactifs** pour le d√©bogage et l'analyse.
-   Une **validation statistique rigoureuse** des mod√®les.

...permet d'obtenir des r√©sultats de tr√®s haute qualit√©.

Le projet AstroSpectro a atteint son objectif principal. Le laboratoire est construit, les outils sont aff√ªt√©s, et les r√©sultats sont l√†. L'aventure, bien s√ªr, ne fait que commencer. La [Roadmap](https://phd-brown.github.io/AstroSpectro/docs/community/roadmap) est encore pleine de d√©fis passionnants.

### Perspectives

- **Nouveaux mod√®les √† tester** : CNN, transformers spectraux.
- **Plus grande diversit√© de jeux de donn√©es** : extension au DR6, SDSS...
- **Automatisation compl√®te du pipeline (CI/CD)**.
- **App Streamlit** : vers une interface de classification interactive en ligne.

#### üöÄ *Envie de contribuer ?*  
Forkez le projet, proposez vos id√©es, ou [contactez-moi](https://phd-brown.github.io/AstroSpectro/docs/community/contributing) !
